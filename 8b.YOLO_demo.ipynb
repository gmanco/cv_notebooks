{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection con YOLOv3 in PyTorch\n",
    "\n",
    "In questo notebook useremo un'implementazione PyTorch di YOLOv3. La documentazione originale si può trovare sul sito https://pjreddie.com/darknet/yolo/.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carichiamo i pesi\n",
    "L'autore mette a disposizione l'insieme dei pesi preaddestrati sul [Common Object Contest (COCO) datase](cocodataset.org).\n",
    "\n",
    "Per prima cosa otteniamo i pesi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-07 14:42:03--  https://pjreddie.com/media/files/yolov3.weights\n",
      "Risoluzione di pjreddie.com (pjreddie.com)... 128.208.4.108\n",
      "Connessione a pjreddie.com (pjreddie.com)|128.208.4.108|:443... connesso.\n",
      "Richiesta HTTP inviata, in attesa di risposta... 200 OK\n",
      "Lunghezza: 248007048 (237M) [application/octet-stream]\n",
      "Salvataggio in: «./yolov3.weights»\n",
      "\n",
      "./yolov3.weights    100%[===================>] 236,52M  9,14MB/s    in 23s     \n",
      "\n",
      "2022-04-07 14:42:28 (10,3 MB/s) - «./yolov3.weights» salvato [248007048/248007048]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://pjreddie.com/media/files/yolov3.weights -O ./yolov3.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inizializziamo il modello\n",
    "\n",
    "Il codice che implementa l'achitettura si trova nella directory `yolo_pytorch`. Date un'occhiata all'implementazione e cercate di capire com'è strutturata l'architettura. \n",
    "\n",
    "\n",
    "L'implementazione utilizzata è basata su quella di Ultralytics, disponibile su https://github.com/ultralytics/yolov3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beppe/opt/anaconda3/envs/ptc/lib/python3.9/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/Users/beppe/opt/anaconda3/envs/ptc/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: /Users/beppe/opt/anaconda3/envs/ptc/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Expected in: /Users/beppe/opt/anaconda3/envs/ptc/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch 1.9.0.post2\n",
      "Darknet(\n",
      "  (module_list): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_0): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_1): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (conv_2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_2): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_3): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (shortcut_4): EmptyLayer()\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (conv_5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (batch_norm_5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_5): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_6): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_7): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (8): Sequential(\n",
      "      (shortcut_8): EmptyLayer()\n",
      "    )\n",
      "    (9): Sequential(\n",
      "      (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_9): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (10): Sequential(\n",
      "      (conv_10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_10): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (11): Sequential(\n",
      "      (shortcut_11): EmptyLayer()\n",
      "    )\n",
      "    (12): Sequential(\n",
      "      (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (batch_norm_12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_12): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (13): Sequential(\n",
      "      (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_13): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (14): Sequential(\n",
      "      (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_14): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (15): Sequential(\n",
      "      (shortcut_15): EmptyLayer()\n",
      "    )\n",
      "    (16): Sequential(\n",
      "      (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_16): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (17): Sequential(\n",
      "      (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_17): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (18): Sequential(\n",
      "      (shortcut_18): EmptyLayer()\n",
      "    )\n",
      "    (19): Sequential(\n",
      "      (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_19): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (20): Sequential(\n",
      "      (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_20): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (21): Sequential(\n",
      "      (shortcut_21): EmptyLayer()\n",
      "    )\n",
      "    (22): Sequential(\n",
      "      (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_22): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (23): Sequential(\n",
      "      (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_23): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (24): Sequential(\n",
      "      (shortcut_24): EmptyLayer()\n",
      "    )\n",
      "    (25): Sequential(\n",
      "      (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_25): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (26): Sequential(\n",
      "      (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_26): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (27): Sequential(\n",
      "      (shortcut_27): EmptyLayer()\n",
      "    )\n",
      "    (28): Sequential(\n",
      "      (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_28): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (29): Sequential(\n",
      "      (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_29): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (30): Sequential(\n",
      "      (shortcut_30): EmptyLayer()\n",
      "    )\n",
      "    (31): Sequential(\n",
      "      (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_31): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (32): Sequential(\n",
      "      (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_32): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (33): Sequential(\n",
      "      (shortcut_33): EmptyLayer()\n",
      "    )\n",
      "    (34): Sequential(\n",
      "      (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_34): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (35): Sequential(\n",
      "      (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_35): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (36): Sequential(\n",
      "      (shortcut_36): EmptyLayer()\n",
      "    )\n",
      "    (37): Sequential(\n",
      "      (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (batch_norm_37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_37): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (38): Sequential(\n",
      "      (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_38): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (39): Sequential(\n",
      "      (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_39): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (40): Sequential(\n",
      "      (shortcut_40): EmptyLayer()\n",
      "    )\n",
      "    (41): Sequential(\n",
      "      (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_41): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (42): Sequential(\n",
      "      (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_42): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (43): Sequential(\n",
      "      (shortcut_43): EmptyLayer()\n",
      "    )\n",
      "    (44): Sequential(\n",
      "      (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_44): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (45): Sequential(\n",
      "      (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_45): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (46): Sequential(\n",
      "      (shortcut_46): EmptyLayer()\n",
      "    )\n",
      "    (47): Sequential(\n",
      "      (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_47): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (48): Sequential(\n",
      "      (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_48): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (49): Sequential(\n",
      "      (shortcut_49): EmptyLayer()\n",
      "    )\n",
      "    (50): Sequential(\n",
      "      (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_50): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (51): Sequential(\n",
      "      (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_51): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (52): Sequential(\n",
      "      (shortcut_52): EmptyLayer()\n",
      "    )\n",
      "    (53): Sequential(\n",
      "      (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_53): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (54): Sequential(\n",
      "      (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_54): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (55): Sequential(\n",
      "      (shortcut_55): EmptyLayer()\n",
      "    )\n",
      "    (56): Sequential(\n",
      "      (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_56): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_56): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (57): Sequential(\n",
      "      (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_57): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_57): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (58): Sequential(\n",
      "      (shortcut_58): EmptyLayer()\n",
      "    )\n",
      "    (59): Sequential(\n",
      "      (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_59): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_59): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (60): Sequential(\n",
      "      (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_60): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (61): Sequential(\n",
      "      (shortcut_61): EmptyLayer()\n",
      "    )\n",
      "    (62): Sequential(\n",
      "      (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (batch_norm_62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_62): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (63): Sequential(\n",
      "      (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_63): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (64): Sequential(\n",
      "      (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_64): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_64): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (65): Sequential(\n",
      "      (shortcut_65): EmptyLayer()\n",
      "    )\n",
      "    (66): Sequential(\n",
      "      (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_66): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (67): Sequential(\n",
      "      (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_67): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (68): Sequential(\n",
      "      (shortcut_68): EmptyLayer()\n",
      "    )\n",
      "    (69): Sequential(\n",
      "      (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_69): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_69): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (70): Sequential(\n",
      "      (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_70): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_70): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (71): Sequential(\n",
      "      (shortcut_71): EmptyLayer()\n",
      "    )\n",
      "    (72): Sequential(\n",
      "      (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_72): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_72): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (73): Sequential(\n",
      "      (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_73): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (74): Sequential(\n",
      "      (shortcut_74): EmptyLayer()\n",
      "    )\n",
      "    (75): Sequential(\n",
      "      (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_75): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_75): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (76): Sequential(\n",
      "      (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_76): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (77): Sequential(\n",
      "      (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_77): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_77): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (78): Sequential(\n",
      "      (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_78): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (79): Sequential(\n",
      "      (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_79): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_79): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (80): Sequential(\n",
      "      (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_80): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_80): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (81): Sequential(\n",
      "      (conv_81): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (82): Sequential(\n",
      "      (yolo_82): YOLOLayer()\n",
      "    )\n",
      "    (83): Sequential(\n",
      "      (route_83): EmptyLayer()\n",
      "    )\n",
      "    (84): Sequential(\n",
      "      (conv_84): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_84): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_84): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (85): Sequential(\n",
      "      (upsample_85): Upsample()\n",
      "    )\n",
      "    (86): Sequential(\n",
      "      (route_86): EmptyLayer()\n",
      "    )\n",
      "    (87): Sequential(\n",
      "      (conv_87): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_87): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_87): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (88): Sequential(\n",
      "      (conv_88): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_88): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_88): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (89): Sequential(\n",
      "      (conv_89): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_89): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_89): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (90): Sequential(\n",
      "      (conv_90): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_90): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_90): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (91): Sequential(\n",
      "      (conv_91): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_91): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_91): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (92): Sequential(\n",
      "      (conv_92): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_92): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_92): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (93): Sequential(\n",
      "      (conv_93): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (94): Sequential(\n",
      "      (yolo_94): YOLOLayer()\n",
      "    )\n",
      "    (95): Sequential(\n",
      "      (route_95): EmptyLayer()\n",
      "    )\n",
      "    (96): Sequential(\n",
      "      (conv_96): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_96): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_96): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (97): Sequential(\n",
      "      (upsample_97): Upsample()\n",
      "    )\n",
      "    (98): Sequential(\n",
      "      (route_98): EmptyLayer()\n",
      "    )\n",
      "    (99): Sequential(\n",
      "      (conv_99): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_99): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_99): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (100): Sequential(\n",
      "      (conv_100): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_100): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_100): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (101): Sequential(\n",
      "      (conv_101): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_101): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_101): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (102): Sequential(\n",
      "      (conv_102): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_102): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_102): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (103): Sequential(\n",
      "      (conv_103): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm_103): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_103): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (104): Sequential(\n",
      "      (conv_104): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm_104): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leaky_104): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (105): Sequential(\n",
      "      (conv_105): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (106): Sequential(\n",
      "      (yolo_106): YOLOLayer()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import yolo_pytorch.models as models\n",
    "from yolo_pytorch.utils.utils import *\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import cv2\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageEnhance\n",
    "\n",
    "print(\"Using PyTorch\", torch.__version__)\n",
    "\n",
    "# Set up model\n",
    "model_config = 'yolo_pytorch/yolov3.cfg'\n",
    "img_size = 416\n",
    "weights = \"./yolov3.weights\"\n",
    "\n",
    "model = models.Darknet(model_config, img_size)\n",
    "# Use GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "models.load_darknet_weights(model, weights)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usiamo il modello per individuare gli oggetti\n",
    "\n",
    "il modello prende in input un'immagine 416x416 e restituisce una lista di descrittori. Incapsuliamo tutto in un detector. \n",
    "\n",
    "\n",
    "\n",
    "### Create functions to detect and display objects\n",
    "We'll create a couple of functions:\n",
    "\n",
    "- **detect_objects**: Submits an image to the model and returns predicted object locations\n",
    "- **show_objects**: Displays the image with a bounding box fo each detected object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Detector:\n",
    "    def __init__(self,model):\n",
    "    \n",
    "        self.model = model\n",
    "        self.classes = load_classes('yolo_pytorch/coco.names')\n",
    "\n",
    "                \n",
    "        # Get bounding-box colors\n",
    "        cmap = plt.get_cmap('tab20b')\n",
    "        self.bbox_colors = [cmap(i) for i in np.linspace(0, 1, len(self.classes))]\n",
    "\n",
    "    \n",
    "    def detect_objects(self, img):\n",
    "    \n",
    "        # Set the model to evaluation mode\n",
    "        self.model.eval()\n",
    "    \n",
    "        # Get scaled width and height\n",
    "        ratio = min(img_size/img.size[0], img_size/img.size[1])\n",
    "        imw = round(img.size[0] * ratio)\n",
    "        imh = round(img.size[1] * ratio)\n",
    "\n",
    "        # Transform the image for prediction\n",
    "        img_transforms = transforms.Compose([\n",
    "            transforms.Resize((imh, imw)),\n",
    "            transforms.Pad((max(int((imh-imw)/2),0), \n",
    "                            max(int((imw-imh)/2),0), \n",
    "                            max(int((imh-imw)/2),0), \n",
    "                            max(int((imw-imh)/2),0)),\n",
    "                           (128,128,128)),\n",
    "            transforms.ToTensor(),\n",
    "         ])\n",
    "    \n",
    "        # convert image to a Tensor\n",
    "        image_tensor = img_transforms(img).float()\n",
    "        if torch.cuda.is_available():\n",
    "            image_tensor = image_tensor.cuda()\n",
    "        image_tensor = image_tensor.unsqueeze_(0)\n",
    "    \n",
    "        # Use the model to detect objects in the image\n",
    "        with torch.no_grad():\n",
    "            detections = self.model(image_tensor)\n",
    "            # Eliminate duplicates with non-max suppression\n",
    "            detections = non_max_suppression(detections, 0.8, 0.4)\n",
    "        return detections[0]\n",
    "\n",
    "    \n",
    "    def generate_bb(self, img):\n",
    "        \n",
    "        original_size = img.size  # W x H\n",
    "        pad_x = max(img.size[0] - img.size[1], 0) * (img_size / max(img.size))\n",
    "        pad_y = max(img.size[1] - img.size[0], 0) * (img_size / max(img.size))\n",
    "        unpad_h = img_size - pad_y\n",
    "        unpad_w = img_size - pad_x\n",
    "        \n",
    "        detections = self.detect_objects(img)\n",
    "\n",
    "        if detections is not None:\n",
    "            # process each instance of each class that was found\n",
    "            unique_labels = detections[:, -1].cpu().unique()\n",
    "            n_cls_preds = len(unique_labels)\n",
    "            # browse detections and draw bounding boxes\n",
    "            for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections:\n",
    "                \n",
    "                # etichetta di classe\n",
    "                predicted_class = self.classes[int(cls_pred)]\n",
    "\n",
    "                color = self.bbox_colors[int(np.where(unique_labels == int(cls_pred))[0])]\n",
    "                cur_color = (int(color[0] * 255), int(color[1] * 255), int(color[2] * 255))\n",
    "            \n",
    "                # L'etichetta da attaccare\n",
    "                label = '{}\\n{:.2f}'.format(predicted_class, cls_conf)\n",
    "\n",
    "                # compute coord for ImageDraw\n",
    "                # dimensioni del box\n",
    "                box_h = ((y2 - y1) / unpad_h) * original_size[0]\n",
    "                box_w = ((x2 - x1) / unpad_w) * original_size[1]\n",
    "                y1 = ((y1 - pad_x // 2) / unpad_h) * original_size[0]\n",
    "                x1 = ((x1 - pad_y // 2) / unpad_w) * original_size[1]\n",
    "                \n",
    "#            cv2.rectangle(img, (x1, y1), (x1 + box_w, y1 + box_h),cur_color, 2)\n",
    "#            cv2.putText(img,label, (x1, y1), font, fontScale,cur_color,2)\n",
    "            \n",
    "                draw = ImageDraw.Draw(img)\n",
    "                draw.rectangle(((x1, y1), (x1 + box_w, y1 + box_h)), fill=None, outline=cur_color)\n",
    "            \n",
    "                # font = ImageFont.truetype(\"font_path123\")\n",
    "                font = ImageFont.load_default()\n",
    "                draw.text((x1, y1), label, font=font, outline=cur_color)\n",
    "\n",
    "        return img, len(detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the functions with test images\n",
    "Now we're ready to get some predictions from our test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from IPython.display import clear_output, display, Image as IPImage\n",
    "from PIL import Image\n",
    "\n",
    "def showarray(a, fmt='jpeg'):\n",
    "    f = BytesIO()\n",
    "    Image.fromarray(a).save(f, fmt)\n",
    "    display(IPImage(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream stopped\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "#cam = cv2.VideoCapture('P1033731.mp4')\n",
    "cam = cv2.VideoCapture('small.mp4')\n",
    "\n",
    "detector = Detector(model)\n",
    "\n",
    "try:\n",
    "    while(True):\n",
    "        t1 = time.time()\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cam.read()\n",
    "        # to display the image\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(frame)\n",
    "        \n",
    "        frame, len_detections = detector.generate_bb(img)\n",
    "        # Display the image with bounding boxes\n",
    "        #showarray(frame)\n",
    "        display(img)\n",
    "        \n",
    "        t2 = time.time()\n",
    "        # How many objects did we detect?\n",
    "        print('Found {} objects, {} FPS'.format(len_detections, (1/(t2-t1))))\n",
    "        # Display the frame until new frame is available\n",
    "\n",
    "        clear_output(wait=True)\n",
    "except KeyboardInterrupt:\n",
    "    cam.release()\n",
    "    print(\"Stream stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
