{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retinanet\n",
    "\n",
    "Retinanet è un esempio di architettura di rete single stage. È costituita da un modulo principale chiamato *backbone* e da due moduli secondari chiamati *subnetwork*. Il primo estrae le feature map dall'intera immagine mentre le subnet costituiscono i moduli di classificazione e regressione.\n",
    "\n",
    "![](retinanet.png)\n",
    "\n",
    "La rete di Backbone è costituita dal Feature Pyramid Network (FPN). Essenzialmente vengono estratte delle feature map a differenti valori di scale con lo scopo di identificare oggetti di dimensione diversa.\n",
    "\n",
    "La rete combina le feature *semanticamente forti* a bassa risoluzione con caratteristiche *semanticamente deboli* ad alta risoluzione tramite un Top-Down path e con connessioni laterali.\n",
    "\n",
    "![](fpn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.model_zoo as model_zoo\n",
    "from torchvision.models.resnet import BasicBlock, Bottleneck, ResNet\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "class BasicBlockFeatures(BasicBlock):\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, tuple):\n",
    "            x = x[0]\n",
    "\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        conv2_rep = out\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out, conv2_rep\n",
    "\n",
    "\n",
    "class BottleneckFeatures(Bottleneck):\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, tuple):\n",
    "            x = x[0]\n",
    "\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        conv3_rep = out\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out, conv3_rep\n",
    "\n",
    "\n",
    "class ResNetFeatures(ResNet):\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x, c2 = self.layer1(x)\n",
    "        x, c3 = self.layer2(x)\n",
    "        x, c4 = self.layer3(x)\n",
    "        x, c5 = self.layer4(x)\n",
    "\n",
    "        return c2, c3, c4, c5\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    model = ResNetFeatures(BasicBlockFeatures, [2, 2, 2, 2], **kwargs)\n",
    "\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    model = ResNetFeatures(BasicBlockFeatures, [3, 4, 6, 3], **kwargs)\n",
    "\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    model = ResNetFeatures(BottleneckFeatures, [3, 4, 6, 3], **kwargs)\n",
    "\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    model = ResNetFeatures(BottleneckFeatures, [3, 4, 23, 3], **kwargs)\n",
    "\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    model = ResNetFeatures(BottleneckFeatures, [3, 8, 36, 3], **kwargs)\n",
    "\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_layer_init(tensor, pi=0.01):\n",
    "    fill_constant = - math.log((1 - pi) / pi)\n",
    "    if isinstance(tensor, Variable):\n",
    "        classification_layer_init(tensor.data)\n",
    "    return tensor.fill_(fill_constant)\n",
    "\n",
    "def init_conv_weights(layer):\n",
    "    nn.init.normal(layer.weight.data, std=0.01)\n",
    "    nn.init.constant(layer.bias.data, val=0)\n",
    "    return layer\n",
    "\n",
    "def conv1x1(in_channels, out_channels, **kwargs):\n",
    "    layer = nn.Conv2d(in_channels, out_channels, kernel_size=1, **kwargs)\n",
    "    layer = init_conv_weights(layer)\n",
    "    return layer\n",
    "\n",
    "def conv3x3(in_channels, out_channels, **kwargs):\n",
    "    layer = nn.Conv2d(in_channels, out_channels, kernel_size=3, **kwargs)\n",
    "    layer = init_conv_weights(layer)\n",
    "    return layer\n",
    "\n",
    "def upsample(feature, sample_feature, scale_factor=2):\n",
    "    h, w = sample_feature.size()[2:]\n",
    "    return F.upsample(feature, scale_factor=scale_factor)[:, :, :h, :w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturePyramid(nn.Module):\n",
    "    def __init__(self, resnet):\n",
    "        super(FeaturePyramid, self).__init__()\n",
    "\n",
    "        self.resnet = resnet\n",
    "\n",
    "        self.pyramid_transformation_3 = conv1x1(512, 256)\n",
    "        self.pyramid_transformation_4 = conv1x1(1024, 256)\n",
    "        self.pyramid_transformation_5 = conv1x1(2048, 256)\n",
    "\n",
    "        self.pyramid_transformation_6 = conv3x3(2048, 256, padding=1, stride=2)\n",
    "        self.pyramid_transformation_7 = conv3x3(256, 256, padding=1, stride=2)\n",
    "\n",
    "        self.upsample_transform_1 = conv3x3(256, 256, padding=1)\n",
    "        self.upsample_transform_2 = conv3x3(256, 256, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, resnet_feature_3, resnet_feature_4, resnet_feature_5 = self.resnet(x)\n",
    "\n",
    "        pyramid_feature_6 = self.pyramid_transformation_6(resnet_feature_5)\n",
    "        pyramid_feature_7 = self.pyramid_transformation_7(F.relu(pyramid_feature_6))\n",
    "\n",
    "        pyramid_feature_5 = self.pyramid_transformation_5(resnet_feature_5)\n",
    "\n",
    "        pyramid_feature_4 = self.pyramid_transformation_4(resnet_feature_4)\n",
    "        upsampled_feature_5 = upsample(pyramid_feature_5, pyramid_feature_4)\n",
    "        pyramid_feature_4 = self.upsample_transform_1(torch.add(upsampled_feature_5, pyramid_feature_4))\n",
    "        \n",
    "        pyramid_feature_3 = self.pyramid_transformation_3(resnet_feature_3)\n",
    "        upsampled_feature_4 = upsample(pyramid_feature_4, pyramid_feature_3)\n",
    "        pyramid_feature_3 = self.upsample_transform_2(torch.add(upsampled_feature_4, pyramid_feature_3))\n",
    "\n",
    "        return pyramid_feature_3, pyramid_feature_4, pyramid_feature_5, pyramid_feature_6, pyramid_feature_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubNet(nn.Module):\n",
    "    def __init__(self, k, anchors=9, depth=4, activation=F.relu):\n",
    "        super(SubNet, self).__init__()\n",
    "        self.anchors = anchors\n",
    "        self.activation = activation\n",
    "        self.base = nn.ModuleList([conv3x3(256, 256, padding=1) for _ in range(depth)])\n",
    "        self.output = nn.Conv2d(256, k * anchors, kernel_size=3, padding=1)\n",
    "        classification_layer_init(self.output.weight.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.base:\n",
    "            x = self.activation(layer(x))\n",
    "        x = self.output(x)\n",
    "        x = x.permute(0, 2, 3, 1).contiguous().view(x.size(0), x.size(2) * x.size(3) * self.anchors, -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinaNet(nn.Module):\n",
    "    backbones = {\n",
    "        'resnet18': resnet18,\n",
    "        'resnet34': resnet34,\n",
    "        'resnet50': resnet50,\n",
    "        'resnet101': resnet101,\n",
    "        'resnet152': resnet152\n",
    "    }\n",
    "\n",
    "    def __init__(self, backbone='resnet101', num_classes=20, pretrained=True):\n",
    "        super(RetinaNet, self).__init__()\n",
    "        self.resnet = RetinaNet.backbones[backbone](pretrained=pretrained)\n",
    "        self.feature_pyramid = FeaturePyramid(self.resnet)\n",
    "        self.subnet_boxes = SubNet(4)\n",
    "        self.subnet_classes = SubNet(num_classes + 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pyramid_features = self.feature_pyramid(x)\n",
    "        class_predictions = [self.subnet_classes(p) for p in pyramid_features]\n",
    "        bbox_predictions = [self.subnet_boxes(p) for p in pyramid_features]\n",
    "        return torch.cat(bbox_predictions, 1), torch.cat(class_predictions, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss\n",
    "\n",
    "L'altra innovazione introdotta in RetinaNet è la formulazione della loss. Come gestire il problema delle classi sbilanciate?\n",
    "\n",
    "Il numero degli anchor box negativi è molto maggiore dei box positivi. Soluzione: pesare opportunamente le predizioni corrette rispetto a quelle errate.\n",
    "\n",
    "![](focal_loss.png)\n",
    "\n",
    "dove $\\alpha_t$ è un parametro di bilanciamento, $p_t$ è la probabilità associata alla classe *t*, $\\gamma$ è definito come *focusing parameter*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
