{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ProgettoCV3.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOhpwKE9NAxJHEOAmHEwSUh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"z75ciAsvSVrM"},"source":["## CARICAMENTO LIBRERIE E DATASET"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"etW3mC5TqnoF","executionInfo":{"status":"ok","timestamp":1623609666616,"user_tz":-120,"elapsed":22638,"user":{"displayName":"Serafino Salatino","photoUrl":"","userId":"17776158785149671781"}},"outputId":"974236e9-67a2-45a9-d447-3c0c0fd80efb"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cZCs_XczrMZR"},"source":["!tar -xvf /content/drive/MyDrive/labeled.tgz -C /content/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JQYJcNBZrYeh","executionInfo":{"status":"ok","timestamp":1624641762391,"user_tz":-120,"elapsed":3867,"user":{"displayName":"Serafino Salatino","photoUrl":"","userId":"17776158785149671781"}}},"source":["SEED = 9246\n","\n","import os\n","import json\n","import time\n","from datetime import datetime\n","import collections\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision\n","from torchvision import models\n","\n","from PIL import Image\n","\n","from skimage import io\n","import pandas as pd\n","import numpy as np\n","np.random.seed(SEED)\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from sklearn.metrics import classification_report\n","\n","import torchsummary\n","import random\n","import cv2\n","\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","\n","CUDA = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if CUDA else \"cpu\")\n","\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NMWbeT3RrbuE","executionInfo":{"status":"ok","timestamp":1623609837275,"user_tz":-120,"elapsed":16,"user":{"displayName":"Serafino Salatino","photoUrl":"","userId":"17776158785149671781"}},"outputId":"abe0af23-3b5e-4306-99b8-1c810200e637"},"source":["DATASET_DIR = '/content/progetto_2021_dataset'\n","DRIVE_FOLDER = '/content/drive/MyDrive/progetto_2021/model_checkpoint3'\n","DATASET_UNLABELED = '/content/progetto_2021_dataset/unlabeled1'\n","DATASET_UNLABELED2 = '/content/progetto_2021_dataset/unlabeled2'\n","\n","JSON_DATA = os.path.join(DATASET_DIR, 'train_test_split_dict.json')\n","\n","with open(JSON_DATA) as fp:\n","    dataset_json = json.load(fp)\n","    \n","len(dataset_json)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"1BEsqS3_re7o"},"source":["labels = set()\n","\n","for k in dataset_json.values():\n","    for lable_list in k.values():\n","        for v in lable_list:\n","            labels.add(v)\n","            \n","label_idx = {v: i for i, v in enumerate(sorted(labels))}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KoWoxfp8rjWB"},"source":["import time\n","\n","class VideoDataset(Dataset):\n","\n","    def load_images_from_folder(self,folder):\n","      images = []\n","      for filename in os.listdir(folder):\n","          img = cv2.imread(os.path.join(folder,filename))\n","          if img is not None:\n","              images.append(img)\n","      return images\n","\n","    def __init__(self, dataset_folder, labels_dict, transform=None, limit=30):\n","        \"\"\"\n","        Args:\n","            dataset_folder (string): Path to the folder with mp4 files.\n","            labels_dict (dict): dict filename - list of label.\n","            transform (callable, optional): Optional transform to be applied\n","                on a sample.\n","        \"\"\"\n","        self.labels_dict = labels_dict\n","        self.root_dir = dataset_folder\n","        self.limit = limit\n","        self.transform = transform or torchvision.transforms.ToTensor()\n","        \n","        self._files = np.array(list(self.labels_dict.keys()))\n","\n","    def __len__(self):\n","        return len(self.labels_dict)\n","\n","    def __getitem__(self, idx):\n","        name = self._files[idx]\n","        \n","        x = torch.zeros(self.limit, 3, 224, 224)\n","        #folder_pattern = os.path.join(self.root_dir, name,'*.png')\n","        #images = io.imread_collection(folder_pattern)\n","\n","        folder = os.path.join(self.root_dir,name)\n","        images = self.load_images_from_folder(folder)    \n","\n","\n","        \n","        j = 0     \n","        for i, image in enumerate(images):\n","            if i < self.limit:\n","                j += 1\n","                image = Image.fromarray(image)\n","                image = self.transform(image)\n","                x[i] = image.unsqueeze(0)\n","\n","        #if j < self.limit :\n","            #immagini = self.limit - j\n","            #for  k in range(immagini):\n","                #rand = random.randint(0,j-1)\n","                #image = images[rand]\n","                #image = Image.fromarray(image)\n","                #image = self.transform(image)\n","                #x[k+j] = image.unsqueeze(0)\n","      \n","\n","\n","        labels = torch.zeros(len(label_idx), dtype=torch.float32)\n","        for label in self.labels_dict[name]:\n","            labels[label_idx[label]] = 1\n","        \n","        return x, labels\n","\n","\n","transformations = torchvision.transforms.Compose([torchvision.transforms.CenterCrop(224),\n","                                                  torchvision.transforms.ToTensor(),\n","                                                  #torchvision.transforms.RandomAffine(30),\n","                                                  #torchvision.transforms.RandomHorizontalFlip()\n","                                                  ])\n","\n","datasetTrain = VideoDataset(DATASET_DIR, dataset_json['train'], transformations,limit=20)\n","datasetTest = VideoDataset(DATASET_DIR, dataset_json['test'], transformations,limit=20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E1cIv4aprnNk"},"source":["batch_size = 16\n","trainingDataLoader = torch.utils.data.DataLoader(datasetTrain, \n","                                                 batch_size=batch_size, \n","                                                 shuffle=True, \n","                                                 num_workers=2,\n","                                                 drop_last=True)\n","testDataLoader = torch.utils.data.DataLoader(datasetTest, \n","                                             batch_size=batch_size,\n","                                             shuffle=True,\n","                                             drop_last=True, \n","                                             num_workers=2)\n","\n","#UnlabeledDataLoader = torch.utils.data.DataLoader(datasetUnlabeled, \n"," #                                            batch_size=batch_size,\n"," #                                            shuffle=True,\n"," #                                            drop_last=True, \n"," #                                            num_workers=2)\n","#Unlabeled2DataLoader = torch.utils.data.DataLoader(datasetUnlabeled2, \n"," #                                            batch_size=batch_size,\n","  #                                           shuffle=True,\n","   #                                          drop_last=True, \n","    #                                         num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pl2cEMPdSfZ_"},"source":["## MODELLO"]},{"cell_type":"code","metadata":{"id":"vz1utrKcrpsA"},"source":["import torchvision.models as models\n","\n","resnet = models.vgg19(pretrained = True)\n","\n","for params in resnet.parameters():\n","  params.requires_grad = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hLFwlD_drsz2"},"source":["class Identity(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","    def forward(self, x):\n","        return x\n","\n","resnet.fc = Identity()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SCicpwT3rwKl","executionInfo":{"status":"ok","timestamp":1624641767840,"user_tz":-120,"elapsed":271,"user":{"displayName":"Serafino Salatino","photoUrl":"","userId":"17776158785149671781"}}},"source":["dense = nn.Sequential(\n","    nn.Conv1d(20,20,kernel_size=(3),padding=1,stride=2),\n","    nn.ReLU(),\n","    nn.BatchNorm1d(20),\n","    nn.Conv1d(20,32,kernel_size=(5),padding=1,stride=2),\n","    nn.ReLU(),\n","    nn.BatchNorm1d(32),\n","    nn.Conv1d(32,64,kernel_size=(5),padding=1,stride=2),\n","    nn.ReLU(),\n","    nn.BatchNorm1d(64),\n","    nn.MaxPool1d(2),\n","    nn.Dropout(0.5),\n","    nn.Conv1d(64,64,kernel_size=(7),padding=1,stride=2),\n","    nn.ReLU(),\n","    nn.BatchNorm1d(64),\n","    nn.Conv1d(64,64,kernel_size=(7),padding=1,stride=2),\n","    nn.ReLU(),\n","    nn.BatchNorm1d(64),\n","    nn.MaxPool1d(2),\n","    nn.Dropout(0.5),\n","    nn.Flatten(),\n","    nn.Linear(384,85),\n","    nn.Sigmoid()\n",")"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"1CJPQnzOrzJM"},"source":["class SGNet(nn.Module):\n","    def __init__(self,resnet,dense):\n","      super().__init__()\n","      self.resnet = resnet\n","      self.dense = dense\n","\n","    def forward(self,x):\n","      batch = torch.zeros((16,20,1000))\n","      i = 0\n","      for trailer in x:\n","          output = self.resnet(trailer) \n","          batch[i] = output\n","          i +=1\n","      result = self.dense(batch.to(device))\n","      return result  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"auPn7No8sFh7"},"source":["model = SGNet(resnet,dense)\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LFRSG8iqSmyW"},"source":["## SALVATAGGIO E CARICAMENTO MODELLO"]},{"cell_type":"code","metadata":{"id":"nFm99E9csLrT"},"source":["CHECKPOINT = os.path.join(DRIVE_FOLDER, 'model.checkpoint')\n","MODELFILE = os.path.join(DRIVE_FOLDER, 'model.pth')\n","\n","def save_checkpoint(epoch, model, optimizer, loss):\n","    torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'loss': loss,\n","            }, CHECKPOINT)\n","\n","def load_checkpoint(model, optimizer):\n","    if not os.path.exists(CHECKPOINT):\n","        return None, None\n","    checkpoint = torch.load(CHECKPOINT)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    epoch = checkpoint['epoch']\n","    loss = checkpoint['loss']\n","    return epoch, loss\n","\n","def save_model(model):\n","    torch.save(model.state_dict(), MODELFILE)\n","\n","def load_lodel(model):\n","    if os.path.exists(MODELFILE):\n","        model.load_state_dict(torch.load(MODELFILE))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4isxPpG2s5G2"},"source":["load_lodel(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zXyflvv5Sreg"},"source":["## DEFINIZIONE LOSS E OTTIMIZZATORE"]},{"cell_type":"code","metadata":{"id":"GH-JHXCAs4Yr"},"source":["#Loss\n","#weight = torch.tensor(weight).to(device)\n","criterion = nn.BCELoss()\n","\n","#optimizer\n","optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n","\n","epoca = 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7_5IYuf3S2Tb"},"source":["## FASE DI TRAINING "]},{"cell_type":"code","metadata":{"id":"DL_TZStns7Vf"},"source":["epoca, error = load_checkpoint(model,optimizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Nx-Jkj_sSIv","executionInfo":{"status":"ok","timestamp":1623619382774,"user_tz":-120,"elapsed":9245210,"user":{"displayName":"Serafino Salatino","photoUrl":"","userId":"17776158785149671781"}},"outputId":"ac595762-88e0-4d90-ae2a-9d23fc1eb6ae"},"source":["epochs = 50\n","train_losses = []\n","\n","last_epoch = epoca\n","\n","print_every = 20\n","\n","try:\n","    for epoch in range(last_epoch or 0, epochs):\n","        print('Start epoch', epoch+1)\n","        model.train()\n","        running_loss = 0\n","        steps = 0\n","        for x, y in trainingDataLoader:\n","\n","            steps += 1\n","            if epoch == 0 and steps == 1:\n","                print(f'input shape is {x.shape}, labels are {y.shape}')\n","\n","\n","            x = x.view(16,20,3,224,224)\n","            optimizer.zero_grad()\n","            logit = model.forward(x.to(device))\n","\n","            loss = criterion(logit, y.to(device))\n","            loss.backward()\n","\n","            optimizer.step()\n","            running_loss += loss.item()\n","            \n","            # TRAIN unlabeled batch\n","            # ...\n","            \n","            if steps % print_every == 0:\n","                print(f\"epoch {epoch+1}/{epochs} \"\n","                      f\"train loss: {running_loss/steps:.6f} Labeled\")\n","\n","                save_checkpoint(epoch, model, optimizer, loss)\n","\n","        save_model(model)\n","        train_losses.append(running_loss/steps)\n","        print(f\"END Epoch {epoch+1}/{epochs} \"\n","              f\"Train loss: {running_loss/steps:.6f} \")\n","        \n","except KeyboardInterrupt: \n","    print('Exiting from training early')\n","  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Start epoch 18\n","epoch 18/50 train loss: 0.119538 Labeled\n","epoch 18/50 train loss: 0.117859 Labeled\n","epoch 18/50 train loss: 0.117531 Labeled\n","epoch 18/50 train loss: 0.116856 Labeled\n","epoch 18/50 train loss: 0.116823 Labeled\n","epoch 18/50 train loss: 0.115882 Labeled\n","epoch 18/50 train loss: 0.115941 Labeled\n","epoch 18/50 train loss: 0.115530 Labeled\n","epoch 18/50 train loss: 0.115191 Labeled\n","epoch 18/50 train loss: 0.115315 Labeled\n","epoch 18/50 train loss: 0.115425 Labeled\n","epoch 18/50 train loss: 0.115845 Labeled\n","epoch 18/50 train loss: 0.115950 Labeled\n","END Epoch 18/50 Train loss: 0.115825 \n","Start epoch 19\n","epoch 19/50 train loss: 0.117476 Labeled\n","epoch 19/50 train loss: 0.114875 Labeled\n","epoch 19/50 train loss: 0.113381 Labeled\n","epoch 19/50 train loss: 0.114382 Labeled\n","epoch 19/50 train loss: 0.115478 Labeled\n","epoch 19/50 train loss: 0.115519 Labeled\n","epoch 19/50 train loss: 0.114615 Labeled\n","epoch 19/50 train loss: 0.114709 Labeled\n","epoch 19/50 train loss: 0.114691 Labeled\n","epoch 19/50 train loss: 0.115038 Labeled\n","epoch 19/50 train loss: 0.114798 Labeled\n","epoch 19/50 train loss: 0.115422 Labeled\n","epoch 19/50 train loss: 0.115439 Labeled\n","END Epoch 19/50 Train loss: 0.115376 \n","Start epoch 20\n","epoch 20/50 train loss: 0.113055 Labeled\n","epoch 20/50 train loss: 0.114182 Labeled\n","epoch 20/50 train loss: 0.114478 Labeled\n","epoch 20/50 train loss: 0.115653 Labeled\n","epoch 20/50 train loss: 0.114884 Labeled\n","epoch 20/50 train loss: 0.115504 Labeled\n","epoch 20/50 train loss: 0.114515 Labeled\n","epoch 20/50 train loss: 0.115323 Labeled\n","epoch 20/50 train loss: 0.115763 Labeled\n","epoch 20/50 train loss: 0.115653 Labeled\n","epoch 20/50 train loss: 0.115454 Labeled\n","epoch 20/50 train loss: 0.115365 Labeled\n","epoch 20/50 train loss: 0.115689 Labeled\n","END Epoch 20/50 Train loss: 0.115591 \n","Start epoch 21\n","epoch 21/50 train loss: 0.113001 Labeled\n","epoch 21/50 train loss: 0.114172 Labeled\n","epoch 21/50 train loss: 0.115111 Labeled\n","epoch 21/50 train loss: 0.115335 Labeled\n","epoch 21/50 train loss: 0.115384 Labeled\n","epoch 21/50 train loss: 0.114686 Labeled\n","epoch 21/50 train loss: 0.114808 Labeled\n","epoch 21/50 train loss: 0.114845 Labeled\n","epoch 21/50 train loss: 0.114729 Labeled\n","epoch 21/50 train loss: 0.115173 Labeled\n","epoch 21/50 train loss: 0.115016 Labeled\n","epoch 21/50 train loss: 0.115571 Labeled\n","epoch 21/50 train loss: 0.115525 Labeled\n","END Epoch 21/50 Train loss: 0.115288 \n","Start epoch 22\n","epoch 22/50 train loss: 0.123426 Labeled\n","epoch 22/50 train loss: 0.116298 Labeled\n","epoch 22/50 train loss: 0.113839 Labeled\n","epoch 22/50 train loss: 0.114192 Labeled\n","epoch 22/50 train loss: 0.114716 Labeled\n","epoch 22/50 train loss: 0.113953 Labeled\n","epoch 22/50 train loss: 0.114446 Labeled\n","epoch 22/50 train loss: 0.114337 Labeled\n","epoch 22/50 train loss: 0.114537 Labeled\n","epoch 22/50 train loss: 0.114747 Labeled\n","epoch 22/50 train loss: 0.114754 Labeled\n","epoch 22/50 train loss: 0.115145 Labeled\n","epoch 22/50 train loss: 0.115126 Labeled\n","END Epoch 22/50 Train loss: 0.114753 \n","Start epoch 23\n","epoch 23/50 train loss: 0.112427 Labeled\n","epoch 23/50 train loss: 0.114506 Labeled\n","epoch 23/50 train loss: 0.113186 Labeled\n","epoch 23/50 train loss: 0.113433 Labeled\n","epoch 23/50 train loss: 0.114382 Labeled\n","epoch 23/50 train loss: 0.114876 Labeled\n","epoch 23/50 train loss: 0.114845 Labeled\n","epoch 23/50 train loss: 0.114751 Labeled\n","epoch 23/50 train loss: 0.114549 Labeled\n","epoch 23/50 train loss: 0.114055 Labeled\n","epoch 23/50 train loss: 0.113857 Labeled\n","epoch 23/50 train loss: 0.113598 Labeled\n","epoch 23/50 train loss: 0.113633 Labeled\n","END Epoch 23/50 Train loss: 0.113859 \n","Start epoch 24\n","epoch 24/50 train loss: 0.112182 Labeled\n","epoch 24/50 train loss: 0.114013 Labeled\n","epoch 24/50 train loss: 0.113888 Labeled\n","epoch 24/50 train loss: 0.114248 Labeled\n","epoch 24/50 train loss: 0.114694 Labeled\n","epoch 24/50 train loss: 0.113297 Labeled\n","epoch 24/50 train loss: 0.113322 Labeled\n","epoch 24/50 train loss: 0.113820 Labeled\n","epoch 24/50 train loss: 0.113649 Labeled\n","epoch 24/50 train loss: 0.113394 Labeled\n","epoch 24/50 train loss: 0.113193 Labeled\n","epoch 24/50 train loss: 0.113525 Labeled\n","epoch 24/50 train loss: 0.114026 Labeled\n","END Epoch 24/50 Train loss: 0.113859 \n","Start epoch 25\n","epoch 25/50 train loss: 0.108806 Labeled\n","epoch 25/50 train loss: 0.111504 Labeled\n","epoch 25/50 train loss: 0.111962 Labeled\n","epoch 25/50 train loss: 0.111500 Labeled\n","epoch 25/50 train loss: 0.111893 Labeled\n","epoch 25/50 train loss: 0.113353 Labeled\n","epoch 25/50 train loss: 0.113452 Labeled\n","epoch 25/50 train loss: 0.113704 Labeled\n","epoch 25/50 train loss: 0.114479 Labeled\n","epoch 25/50 train loss: 0.114152 Labeled\n","epoch 25/50 train loss: 0.113791 Labeled\n","epoch 25/50 train loss: 0.113629 Labeled\n","epoch 25/50 train loss: 0.113991 Labeled\n","END Epoch 25/50 Train loss: 0.113831 \n","Start epoch 26\n","epoch 26/50 train loss: 0.106270 Labeled\n","epoch 26/50 train loss: 0.108682 Labeled\n","epoch 26/50 train loss: 0.110120 Labeled\n","epoch 26/50 train loss: 0.110096 Labeled\n","epoch 26/50 train loss: 0.110705 Labeled\n","epoch 26/50 train loss: 0.110733 Labeled\n","epoch 26/50 train loss: 0.111624 Labeled\n","epoch 26/50 train loss: 0.112053 Labeled\n","epoch 26/50 train loss: 0.112614 Labeled\n","epoch 26/50 train loss: 0.112580 Labeled\n","epoch 26/50 train loss: 0.112916 Labeled\n","epoch 26/50 train loss: 0.112515 Labeled\n","epoch 26/50 train loss: 0.113012 Labeled\n","END Epoch 26/50 Train loss: 0.113037 \n","Start epoch 27\n","epoch 27/50 train loss: 0.115142 Labeled\n","epoch 27/50 train loss: 0.114090 Labeled\n","epoch 27/50 train loss: 0.114346 Labeled\n","epoch 27/50 train loss: 0.113006 Labeled\n","epoch 27/50 train loss: 0.112748 Labeled\n","epoch 27/50 train loss: 0.112877 Labeled\n","epoch 27/50 train loss: 0.112502 Labeled\n","epoch 27/50 train loss: 0.113482 Labeled\n","epoch 27/50 train loss: 0.113785 Labeled\n","epoch 27/50 train loss: 0.114077 Labeled\n","epoch 27/50 train loss: 0.113629 Labeled\n","epoch 27/50 train loss: 0.113096 Labeled\n","epoch 27/50 train loss: 0.113034 Labeled\n","END Epoch 27/50 Train loss: 0.113042 \n","Start epoch 28\n","epoch 28/50 train loss: 0.110219 Labeled\n","epoch 28/50 train loss: 0.111246 Labeled\n","epoch 28/50 train loss: 0.113262 Labeled\n","epoch 28/50 train loss: 0.112938 Labeled\n","epoch 28/50 train loss: 0.112308 Labeled\n","epoch 28/50 train loss: 0.112885 Labeled\n","epoch 28/50 train loss: 0.112725 Labeled\n","epoch 28/50 train loss: 0.113105 Labeled\n","epoch 28/50 train loss: 0.112982 Labeled\n","epoch 28/50 train loss: 0.112498 Labeled\n","epoch 28/50 train loss: 0.112810 Labeled\n","epoch 28/50 train loss: 0.113413 Labeled\n","epoch 28/50 train loss: 0.112818 Labeled\n","END Epoch 28/50 Train loss: 0.112953 \n","Start epoch 29\n","epoch 29/50 train loss: 0.115657 Labeled\n","epoch 29/50 train loss: 0.113523 Labeled\n","epoch 29/50 train loss: 0.112080 Labeled\n","epoch 29/50 train loss: 0.110892 Labeled\n","epoch 29/50 train loss: 0.112847 Labeled\n","epoch 29/50 train loss: 0.112114 Labeled\n","epoch 29/50 train loss: 0.112430 Labeled\n","epoch 29/50 train loss: 0.111954 Labeled\n","epoch 29/50 train loss: 0.112063 Labeled\n","epoch 29/50 train loss: 0.111810 Labeled\n","epoch 29/50 train loss: 0.111952 Labeled\n","epoch 29/50 train loss: 0.111933 Labeled\n","epoch 29/50 train loss: 0.112100 Labeled\n","END Epoch 29/50 Train loss: 0.112224 \n","Start epoch 30\n","epoch 30/50 train loss: 0.113780 Labeled\n","epoch 30/50 train loss: 0.111132 Labeled\n","epoch 30/50 train loss: 0.110467 Labeled\n","epoch 30/50 train loss: 0.110208 Labeled\n","epoch 30/50 train loss: 0.109571 Labeled\n","epoch 30/50 train loss: 0.110710 Labeled\n","epoch 30/50 train loss: 0.111240 Labeled\n","epoch 30/50 train loss: 0.111187 Labeled\n","epoch 30/50 train loss: 0.111398 Labeled\n","epoch 30/50 train loss: 0.111313 Labeled\n","epoch 30/50 train loss: 0.111420 Labeled\n","epoch 30/50 train loss: 0.112298 Labeled\n","epoch 30/50 train loss: 0.112202 Labeled\n","END Epoch 30/50 Train loss: 0.112374 \n","Start epoch 31\n","epoch 31/50 train loss: 0.107684 Labeled\n","epoch 31/50 train loss: 0.112819 Labeled\n","epoch 31/50 train loss: 0.111243 Labeled\n","epoch 31/50 train loss: 0.111107 Labeled\n","epoch 31/50 train loss: 0.110206 Labeled\n","epoch 31/50 train loss: 0.110846 Labeled\n","epoch 31/50 train loss: 0.111373 Labeled\n","epoch 31/50 train loss: 0.111819 Labeled\n","epoch 31/50 train loss: 0.112047 Labeled\n","epoch 31/50 train loss: 0.111786 Labeled\n","epoch 31/50 train loss: 0.111627 Labeled\n","epoch 31/50 train loss: 0.112072 Labeled\n","epoch 31/50 train loss: 0.111775 Labeled\n","END Epoch 31/50 Train loss: 0.112022 \n","Start epoch 32\n","epoch 32/50 train loss: 0.111687 Labeled\n","epoch 32/50 train loss: 0.111169 Labeled\n","epoch 32/50 train loss: 0.112681 Labeled\n","epoch 32/50 train loss: 0.113207 Labeled\n","epoch 32/50 train loss: 0.112902 Labeled\n","epoch 32/50 train loss: 0.113080 Labeled\n","epoch 32/50 train loss: 0.112714 Labeled\n","epoch 32/50 train loss: 0.112282 Labeled\n","epoch 32/50 train loss: 0.112146 Labeled\n","epoch 32/50 train loss: 0.111615 Labeled\n","epoch 32/50 train loss: 0.111079 Labeled\n","epoch 32/50 train loss: 0.111843 Labeled\n","epoch 32/50 train loss: 0.111702 Labeled\n","END Epoch 32/50 Train loss: 0.111626 \n","Start epoch 33\n","epoch 33/50 train loss: 0.111085 Labeled\n","epoch 33/50 train loss: 0.109665 Labeled\n","epoch 33/50 train loss: 0.109351 Labeled\n","epoch 33/50 train loss: 0.110608 Labeled\n","epoch 33/50 train loss: 0.110490 Labeled\n","epoch 33/50 train loss: 0.110672 Labeled\n","epoch 33/50 train loss: 0.110847 Labeled\n","epoch 33/50 train loss: 0.110519 Labeled\n","epoch 33/50 train loss: 0.110649 Labeled\n","epoch 33/50 train loss: 0.111004 Labeled\n","epoch 33/50 train loss: 0.111312 Labeled\n","epoch 33/50 train loss: 0.111516 Labeled\n","epoch 33/50 train loss: 0.111536 Labeled\n","END Epoch 33/50 Train loss: 0.111422 \n","Start epoch 34\n","Exiting from training early\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0X6rGTyIS9jy"},"source":["## FASE DI TESTING"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BpDUfRTFMPoq","executionInfo":{"status":"ok","timestamp":1623619530704,"user_tz":-120,"elapsed":141384,"user":{"displayName":"Serafino Salatino","photoUrl":"","userId":"17776158785149671781"}},"outputId":"84bbc5e4-988b-4ca2-c309-c05b7c148479"},"source":["topk=10\n","predictions = []\n","y_true = []\n","\n","model.eval()\n","\n","with torch.no_grad():\n","    step = 0\n","    for inputs, labels in testDataLoader:\n","\n","        step += 1\n","        inputs,label = inputs.view(16,20,3,224,224), labels.to(\"cuda\")\n","        logps = model(inputs.to(device))\n","        y_pred = logps\n","\n","        _, idx = y_pred.topk(topk, dim=1)\n","\n","        y_pred = torch.zeros_like(y_pred)\n","        y_pred.scatter_(1, idx, 1)\n","        predictions.append(y_pred.cpu())\n","\n","        y_true.append(label.cpu())\n","\n","y_true, predictions = torch.cat(y_true, axis=0), torch.cat(predictions, axis=0)\n","report = classification_report(y_true, predictions, \n","                               target_names=list(sorted(label_idx.keys())),zero_division=0)\n","print(report)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["                      precision    recall  f1-score   support\n","\n","                LGBT       0.09      0.49      0.15        61\n","              action       0.22      0.95      0.36       190\n","     action_comedies       0.00      0.00      0.00         6\n","           adventure       0.14      0.64      0.23        74\n","   alcohol_addiction       0.00      0.00      0.00         6\n","               alien       0.00      0.00      0.00        12\n","           animation       0.25      0.71      0.38        21\n","            aviation       0.00      0.00      0.00        20\n","        bank_robbery       0.00      0.00      0.00        19\n","              biopic       0.07      0.46      0.12        57\n","             cartoon       0.19      0.38      0.25         8\n","               chase       0.00      0.00      0.00        16\n","            children       0.00      0.00      0.00        12\n","              comedy       0.20      0.95      0.33       209\n","        comedy_drama       0.08      0.48      0.14        65\n","       coming_of_age       0.00      0.00      0.00        11\n","              creepy       0.00      0.00      0.00        10\n","               crime       0.14      0.89      0.25       137\n","                cult       0.00      0.00      0.00         7\n","               death       0.00      0.00      0.00         7\n","       death_penalty       0.00      0.00      0.00         8\n","      disaster_movie       0.00      0.00      0.00        10\n","         documentary       0.00      0.00      0.00        31\n","               drama       0.49      1.00      0.66       541\n","            dystopic       0.00      0.00      0.00        20\n","     erotic_thriller       0.00      0.00      0.00         7\n","           espionage       0.00      0.00      0.00        18\n","              family       0.00      0.00      0.00        10\n","             fantasy       0.14      0.74      0.23        98\n","        fight_scenes       0.00      0.00      0.00        11\n","          friendship       0.00      0.00      0.00         6\n","          futuristic       0.00      0.00      0.00        20\n","            gunfight       0.00      0.00      0.00         9\n","         high_school       0.00      0.00      0.00        11\n","             history       0.00      0.00      0.00        15\n","              horror       0.15      0.93      0.26       136\n","       horror_comedy       0.00      0.00      0.00        26\n","          inbreeding       0.00      0.00      0.00        10\n","             justice       0.00      0.00      0.00        10\n","          loneliness       0.00      0.00      0.00         8\n","                love       0.12      0.05      0.07        20\n","               magic       0.00      0.00      0.00         8\n","        martial_arts       0.00      0.00      0.00        18\n","           melodrama       0.00      0.00      0.00         9\n","            monsters       0.12      0.33      0.18        24\n","              murder       0.00      0.00      0.00        11\n","               music       0.00      0.00      0.00         9\n","             musical       0.09      0.65      0.16        60\n","             mystery       0.08      0.41      0.13        58\n","            neo-noir       0.00      0.00      0.00        14\n","                noir       0.11      0.40      0.18        25\n","              nudity       0.00      0.00      0.00        10\n","          parenthood       0.00      0.00      0.00         9\n","             pirates       0.00      0.00      0.00         6\n","police_investigation       0.00      0.00      0.00        10\n","            politics       0.00      0.00      0.00        13\n","         pornography       0.00      0.00      0.00         4\n","              prison       0.00      0.00      0.00        15\n","        prostitution       0.00      0.00      0.00         5\n","            religion       0.00      0.00      0.00         7\n","             revenge       0.00      0.00      0.00        19\n","            romantic       0.10      0.86      0.18        98\n","     romantic_comedy       0.14      0.67      0.23        86\n","               scifi       0.16      0.82      0.27       110\n","       serial_killer       0.00      0.00      0.00        23\n","              sexual       0.08      0.09      0.09        23\n","          small_town       0.00      0.00      0.00         9\n","               space       0.06      0.06      0.06        16\n","            splatter       0.10      0.04      0.06        25\n","               sport       0.00      0.00      0.00        12\n","          super_hero       0.00      0.00      0.00         9\n","        supernatural       0.12      0.24      0.16        25\n","             surreal       0.00      0.00      0.00         8\n","         suspenseful       0.00      0.00      0.00        14\n","          teen_movie       0.00      0.00      0.00        24\n","           terrorism       0.12      0.07      0.09        14\n","            thriller       0.18      0.88      0.30       139\n","         time_travel       0.00      0.00      0.00        12\n","          true_story       0.00      0.00      0.00         9\n","            vampires       0.00      0.00      0.00        12\n","            violence       0.00      0.00      0.00        20\n","                 war       0.09      0.58      0.16        57\n","             wartime       0.08      0.65      0.15        48\n","             western       0.10      0.39      0.16        33\n","             zombies       0.00      0.00      0.00        15\n","\n","           micro avg       0.17      0.61      0.27      3148\n","           macro avg       0.05      0.19      0.07      3148\n","        weighted avg       0.17      0.61      0.26      3148\n","         samples avg       0.17      0.65      0.26      3148\n","\n"],"name":"stdout"}]}]}