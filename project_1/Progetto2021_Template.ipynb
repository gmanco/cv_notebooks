{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zvx2t7ZAzvmL"
   },
   "source": [
    "# Progetto 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6uMeyQHbzvmQ",
    "outputId": "02439096-0f9f-4184-830c-33f6f1912145"
   },
   "outputs": [],
   "source": [
    "SEED = 9246\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import collections\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torchsummary\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if CUDA else \"cpu\")\n",
    "\n",
    "if CUDA:\n",
    "    print('run on cuda %s' % os.environ['CUDA_VISIBLE_DEVICES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VfvRSz8_zvmm"
   },
   "outputs": [],
   "source": [
    "DATASET_DIR = 'progetto_2021_dataset'\n",
    "DRIVE_FOLDER = 'progetto_2021/model_checkpoint'\n",
    "\n",
    "JSON_DATA = os.path.join(DATASET_DIR, 'train_test_split_dict.json')\n",
    "\n",
    "with open(JSON_DATA) as fp:\n",
    "    dataset_json = json.load(fp)\n",
    "    \n",
    "len(dataset_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = set()\n",
    "\n",
    "for k in dataset_json.values():\n",
    "    for lable_list in k.values():\n",
    "        for v in lable_list:\n",
    "            labels.add(v)\n",
    "            \n",
    "label_idx = {v: i for i, v in enumerate(sorted(labels))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f4AJL3nX4Y3t"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ia0Z3U62zvni"
   },
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset_folder, labels_dict, transform=None, limit=30):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset_folder (string): Path to the folder with mp4 files.\n",
    "            labels_dict (dict): dict filename - list of label.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.labels_dict = labels_dict\n",
    "        self.root_dir = dataset_folder\n",
    "        self.limit = limit\n",
    "        self.transform = transform or torchvision.transforms.ToTensor()\n",
    "        \n",
    "        self._files = np.array(list(self.labels_dict.keys()))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_dict)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name = self._files[idx]\n",
    "        \n",
    "        x = torch.zeros(self.limit, 3, 224, 224)\n",
    "        folder_pattern = os.path.join(self.root_dir, name, '*.png')\n",
    "        images = io.imread_collection(folder_pattern)\n",
    "        \n",
    "        for i, image in enumerate(images):\n",
    "            if i < self.limit:\n",
    "                image = self.transform(Image.fromarray(image))\n",
    "                x[i] = image.unsqueeze(0)\n",
    "\n",
    "        labels = torch.zeros(len(label_idx), dtype=torch.float32)\n",
    "        for label in self.labels_dict[name]:\n",
    "            labels[label_idx[label]] = 1\n",
    "        \n",
    "        return x, labels\n",
    "\n",
    "\n",
    "transformations = torchvision.transforms.Compose([torchvision.transforms.CenterCrop(224),\n",
    "                                                  torchvision.transforms.ToTensor()])\n",
    "\n",
    "datasetTrain = VideoDataset(DATASET_DIR, dataset_json['train'], transformations)\n",
    "datasetTest = VideoDataset(DATASET_DIR, dataset_json['test'], transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "trainingDataLoader = torch.utils.data.DataLoader(datasetTrain, \n",
    "                                                 batch_size=batch_size, \n",
    "                                                 shuffle=True, \n",
    "                                                 num_workers=4)\n",
    "testDataLoader = torch.utils.data.DataLoader(datasetTest, \n",
    "                                             batch_size=batch_size, \n",
    "                                             shuffle=True, \n",
    "                                             num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sv2zDTpdzvpD"
   },
   "source": [
    "# Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cGxFpWen2xuC"
   },
   "outputs": [],
   "source": [
    "CHECKPOINT = os.path.join(DRIVE_FOLDER, 'model.checkpoint')\n",
    "MODELFILE = os.path.join(DRIVE_FOLDER, 'model.pth')\n",
    "\n",
    "def save_checkpoint(epoch, model, optimizer, loss):\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, CHECKPOINT)\n",
    "\n",
    "def load_checkpoint(model, optimizer):\n",
    "    if not os.path.exists(CHECKPOINT):\n",
    "        return None, None\n",
    "    checkpoint = torch.load(CHECKPOINT)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "\n",
    "    return epoch, loss\n",
    "\n",
    "def save_model(model):\n",
    "    torch.save(model.state_dict(), MODELFILE)\n",
    "\n",
    "def load_lodel(model):\n",
    "    if os.path.exists(MODELFILE):\n",
    "        model.load_state_dict(torch.load(MODELFILE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "zwNTZTX1zvpy",
    "outputId": "128f9a7a-0a2e-4d57-abb8-9649f5aa81fb"
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "train_losses = []\n",
    "\n",
    "print_every = 100\n",
    "\n",
    "try:\n",
    "    for epoch in range(last_epoch or 0, epochs):\n",
    "        print('Start epoch', epoch+1)\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        steps = 0\n",
    "        for x, y in trainingDataLoader:\n",
    "\n",
    "            steps += 1\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            if epoch == 0 and steps == 1:\n",
    "                print(f'input shape is {x.shape}, labels are {y.shape}')\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logit = model(x)\n",
    "\n",
    "            loss = criterion(logit, y)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # TRAIN unlabeled batch\n",
    "            # ...\n",
    "            \n",
    "            if steps % print_every == 0:\n",
    "                print(f\"epoch {epoch+1}/{epochs} \"\n",
    "                      f\"train loss: {running_loss/steps:.6f} \")\n",
    "\n",
    "                save_checkpoint(epoch, model, optimizer, loss)\n",
    "\n",
    "        save_model(model)\n",
    "        train_losses.append(running_loss/steps)\n",
    "        print(f\"END Epoch {epoch+1}/{epochs} \"\n",
    "              f\"Train loss: {running_loss/steps:.6f} \")\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print('*'*50)\n",
    "            test(model)\n",
    "            print('*'*50)\n",
    "except KeyboardInterrupt: \n",
    "    print('Exiting from training early')\n",
    "\n",
    "save_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "HkfQfAvLzvp5",
    "outputId": "0e0a19d5-7f14-40a1-c7fa-a4140b485345"
   },
   "outputs": [],
   "source": [
    "topk=10\n",
    "predictions = []\n",
    "y_true = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testDataLoader:\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        logps = model(inputs)\n",
    "        y_pred = torch.sigmoid(logps)\n",
    "\n",
    "        _, idx = y_pred.topk(topk, dim=1)\n",
    "\n",
    "        y_pred = torch.zeros_like(y_pred)\n",
    "        y_pred.scatter_(1, idx, 1)\n",
    "        predictions.append(y_pred.cpu())\n",
    "\n",
    "        y_true.append(labels.cpu())\n",
    "\n",
    "\n",
    "y_true, predictions = torch.cat(y_true, axis=0), torch.cat(predictions, axis=0)\n",
    "report = classification_report(y_true, predictions, \n",
    "                               target_names=list(sorted(label_idx.keys())))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SpaceJam.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
